{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d937def0",
   "metadata": {},
   "source": [
    "# 強化学習トレーニングセットアップ\n",
    "このノートブックでは、PyBullet環境でソフトグリッパーの強化学習（PPO）を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインストール（Colab用）\n",
    "!pip install pybullet stable-baselines3 gymnasium opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a79b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import gymnasium as gym\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from pybullet_sim.rl_env import FoodGripperEnv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee9a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境の初期化\n",
    "env = FoodGripperEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab92e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの作成\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, n_steps=2048, batch_size=2048, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f19c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習の実行\n",
    "model.learn(total_timesteps=1_000_000, log_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c9f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "model.save(\"../models/food_gripper_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8dd745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 報酬曲線の可視化\n",
    "rewards = model.logger.get_log_dict().get('rollout/ep_rew_mean', [])\n",
    "plt.plot(rewards)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Mean Reward\")\n",
    "plt.title(\"Training Reward Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from pybullet_sim.rl_env import FoodGripperEnv\n",
    "\n",
    "env = FoodGripperEnv()\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "model.save('models/ppo_gripper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b0a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybullet_sim.rl_env import FoodGripperEnv\n",
    "import numpy as np\n",
    "\n",
    "env = FoodGripperEnv()\n",
    "obs = env.reset()\n",
    "for i in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(f\"step {i}: reward={reward}, done={done}\")\n",
    "    if done:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
